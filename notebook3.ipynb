{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize planar markers using template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 665, 3)\n"
     ]
    }
   ],
   "source": [
    "marker1 = cv2.imread('images/ex3_1.jpg')\n",
    "marker2 = cv2.imread('images/ex3_1b.jpg')\n",
    "\n",
    "print(marker1.shape)\n",
    "\n",
    "\n",
    "cornersMarker1 = np.array([[ 41, 29],\n",
    " [597, 52],\n",
    " [617, 564],\n",
    " [ 39, 557]], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected points: [[385 222]\n",
      " [602 275]\n",
      " [339 343]\n",
      " [567 389]]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('images/ex3_2.jpg')\n",
    "\n",
    "\n",
    "def order_points(pts):\n",
    "\n",
    "\trect = np.zeros((4, 2), dtype = \"float64\")\n",
    "\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "# Define the callback function for mouse events\n",
    "def mouse_callback(event, x, y, flags, params):\n",
    "    # If left button is clicked, record the point coordinates\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        try:\n",
    "            params['points'].append([x, y])\n",
    "            cv2.circle(params['img_select_points'], (x, y), 5, (0, 0, 255), -1)\n",
    "        except:\n",
    "            print('Invalid input')\n",
    "            params['points'].pop()\n",
    "            cv2.circle(params['img_select_points'], (x, y), 5, (0, 0, 0), -1)\n",
    "\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "def select_points_from_image(img_src, no_of_points=4):\n",
    "    img_select_points = img_src.copy()\n",
    "    cv2.namedWindow('image')\n",
    "    params = {'points': [], 'real_coords': [], 'img_select_points': img_select_points}\n",
    "    cv2.setMouseCallback('image', mouse_callback, params)\n",
    "\n",
    "    # Display the image and wait for user to select points\n",
    "    while True:\n",
    "        cv2.imshow('image', img_select_points)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if len(params['points']) == no_of_points:\n",
    "            break\n",
    "\n",
    "    selected_pts = np.array(params['points']) \n",
    "\n",
    "    # Print the selected points\n",
    "    print('Selected points:', selected_pts)\n",
    "    cv2.destroyAllWindows()\n",
    "    return selected_pts\n",
    "\n",
    "\n",
    "cornersImg1 = order_points(select_points_from_image(img1, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.03809170e+00  7.79711886e-01 -9.27881311e+02]\n",
      " [-7.78002735e-01  3.58686794e+00 -4.63705288e+02]\n",
      " [-2.84359577e-04  8.69592868e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "H, _ = cv2.findHomography(cornersImg1, cornersMarker1)\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1500\n",
    "img1_warp = cv2.warpPerspective(img1, H, (img1.shape[1] + offset , img1.shape[0] + offset ))\n",
    "\n",
    "img1_window = cv2.resize(img1_warp, (960, 540)) \n",
    "cv2.imshow('Warp prespective image',img1_window)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_marker1 = img1_warp.copy()\n",
    "marker1_gray = cv2.cvtColor(marker1, cv2.COLOR_BGR2GRAY)\n",
    "img1_warp_gray = cv2.cvtColor(img1_warp, cv2.COLOR_BGR2GRAY)\n",
    "w, h = marker1_gray.shape[::-1]\n",
    "\n",
    "# Apply template Matching\n",
    "res = cv2.matchTemplate(img1_warp_gray,marker1_gray,cv2.TM_CCOEFF_NORMED)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "top_left = max_loc\n",
    "\n",
    "bottom_right = (top_left[0] + w , top_left[1] + h)\n",
    "cv2.rectangle(result_marker1, top_left, bottom_right, (0, 0, 255), 5)\n",
    "\n",
    "result_marker1_window = cv2.resize(result_marker1, (960, 540)) \n",
    "cv2.imshow('Detected point',result_marker1_window)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_marker2 = result_marker1.copy()\n",
    "marker2_gray = cv2.cvtColor(marker2, cv2.COLOR_BGR2GRAY)\n",
    "img1_warp_gray = cv2.cvtColor(result_marker1, cv2.COLOR_BGR2GRAY)\n",
    "w, h = marker1_gray.shape[::-1]\n",
    "\n",
    "# Apply template Matching\n",
    "res = cv2.matchTemplate( img1_warp_gray, marker2_gray,cv2.TM_CCOEFF_NORMED)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "top_left = max_loc\n",
    "\n",
    "bottom_right = (top_left[0] + w , top_left[1] + h)\n",
    "cv2.rectangle(result_marker2, top_left, bottom_right, (0, 255, 0), 5)\n",
    "\n",
    "result_window = cv2.resize(result_marker2, (960, 540)) \n",
    "cv2.imshow('Detected point',result_window)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "IH, _ = cv2.findHomography(cornersMarker1, cornersImg1)\n",
    "img1_back = cv2.warpPerspective(result_marker2, IH, (result_marker2.shape[1] - offset, result_marker2.shape[0] - offset))\n",
    "\n",
    "# Check number of channels\n",
    "img1_back_window = cv2.resize(img1_back, (960, 540)) \n",
    "cv2.imshow('Detected point', img1_back_window)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
